목표
- Non Blocking 자료 구조의 제작 실습
- 일반 자료구조를 멀티쓰레드 자료구조로 변환한다.
- Blocking 자료구조로부터 시작하여 단계별로 성능향상 기법을 적용한다.
- 최종적으로 Lock Free 자료구조를 제작한다.
- 각 자료구조의 성능을 비교한다.

목표 자료구조
- SET
	. 아이템의 중복을 허용하지 않는다.
	. 정렬되어 저장된다. (unordered_set이 아니다)
	  - 검색 효율이 증가한다.
	. 삽입 삭제의 효율성을 위해 연결리스트로 구현된다.
- 구현할 메소드
	. add(x) : 집합에 x 추가, 성공시 true 반환
	. remove(x) : 집합에서 x 제거, 성공시 true 반환
	. contains(x) : 집합에 x가 있다면 true 반환

추가적인 구현
- 보초 노드
	. 검색의 효율성을 위해 항상 존재하는 Head와 Tail 노드를 갖도록 한다.
	. Head는 MAXINT, Tail은 -MAXINT를 키로 갖는다.

구현 차례
성긴 동기화 (coarse-grained synchronization)
- Lock 하나로 동기화 객체 전체를 감싸는 경우
- 성능 향상이 있을 수가 없다.


세밀한 동기화 (fine-grained synchronization)
- 전체 리스트를 한꺼번에 잠그는 것보다 개별 노드를 잠그는 것이 병행성을 향상시킬 수 있다.
	  - 전체 리스트에 대한 잠금을 두는 것이 아니라, 각각의 노드에 잠금을 둔다.
	  - Node에 Lock()과 Unlock() 메소드를 구현해야 한다.
	  - Node의 next field를 변경할 경우에는 반드시 lock을 얻은 후 변경해야 한다.
	. Add()와 Remove() 시점의 Pred, Curr가 가리키는 노드는 locking이 되어 있어야 한다.
	. Head부터 Node 이동을 할 때 lock을 잠그면서 이동해야 한다.
	. 병렬성이 있다.
	  - 그러나 잠금의 획득과 해제가 너무 빈번하다.
	  - 리스트가 길어지는 경우 성능이 매우 떨어진다.
	  - 무조건 head부터 시작하기 때문에 head에 bottle neck이 걸린다.


낙천적인 동기화 (optimistic synchronization_
- 이동 시 잠금을 하지 않는다. -> 오동작의 가능성이 있다.
- add/remove를 위해 prev를 수정하기 전에 prev를 잠근다.
- 이동 시 잠금을 하지 않는다
	. Data Race
	. 세밀한 동기화에서 이동 시 잠그는 이유가 있음.
- 해결
	. Crash (또는 무한루프)
	  - 제거된 Node의 Next가 Crash를 발생시키는 값을 갖지 않게 한다.
	  - 제거된 Node라도 Next를 따라가면 Tail이 나오게 한다.
	. 오동작
	  - prev와 curr를 잠근 후 제대로 잠갔는지 검사. (validation)
	  - prev와 curr를 잘못 잠갔을 경우 처음부터 다시 실행
- 구현 (임시 해결)
	. 제거된 노드를 'delete'하지 않는다.
	  - next 필드의 오염 방지, 결국엔 Tail 만남
	  - 하지만 memory lock -> 나중에 해결
	. validation 조건 검사
	  - 잠겨진 prev와 curr가 제거되지 않았고
	  - prev와 curr 사이에 다른 노드가 끼어들지 않았다.
- Validation
	1. prev, curr가 리스트에 존재한다.
	2. prev와 curr 사이에 다른 노드가 없다.
	. 충분한가? 충분하다.
	. 유효성 검사
	  - 다시 처음부터 검색해서 원래 prev, curr로 다시 올 수 있는지 확인한다.
	  -> prev, curr가 리스트에 존재하는지 확인
	  - prev->next == curr인 것을 확인한다.
	  -> 중간에 다른 노드가 끼어들지 않았음을 확인
- 낙천적 동기화 알고리즘은 기아를 겪을 수 있다.
	. validate가 실패하면 처음부터 다시 실행한다.
	. 다른 쓰레드들이 prev와 curr를 계속 수정하는 경우 계속 재시도를 하면서 지연될 수 있다.
	. 기아상태를 겪는 경우는 흔치 않은 경우이기 때문에 실제로는 잘 동작할 가능성이 크다.


게으른 동기화 (lazy synchronization)
- 낙천적 동기화는 lock의 횟수는 비약적으로 감소했으나 리스트를 두 번 순회해야 한다는
  눈에 보이는 오버헤드가 있다.
- 이를 극복하여 다시 순회하지 않는 알고리즘을 작성하였다.
	. validate()가 노드를 처음부터 다시 순회하지 않고 validation을 수행한다.
	. prev와 curr의 잠금은 여전히 필요하다.
- Contains() 메소드는 자주 호출되는 메소드인데 이 메소드를 wait-free로 만들 수 있으면 좋겠다.
	. 목적이 아니라 부수효과에 가까움
- 각 노드에 marked 필드를 추가하여 그 노드가 집합에서 제거되어 있는지 표시한다.
	. marked가 true이면 제거되었다는 표시
	. marking을 실제 제거보다 반드시 먼저 수행한다.
	  - 또한 marking은 잠금을 획득한 후 수행된다.
	. 순회를 할 때 대상 노드를 잠글 필요가 없고 노드가 head에서 접근할 수 있는지 확인하기 위해
	  전체 리스트를 다시 순회하지 않아도 된다.
- 다음 명제가 반드시 성립한다.
	. marking되어있지 않은 모든 Node는 실제 리스트에 존재하는 살아있는 Node이다.
	. validate에서의 marking 검사는 locking 이후에 이루어지므로 validate가 OK이면 안전하다.

- 단점
	. 게으른 알고리즘은 Blocking이다.
	. 한 쓰레드가 lock을 얻은 채로 지연되면, 다른 쓰레드 역시 지연되게 된다. (convoying)
- 주의
	. flag를 사용할 때 메모리 업데이트 순서가 중요하므로 volatile

메모리 릭의 해결
- Free List
	. Delete하지 않고 모아 놓음
	  - marking이 해제되는 순간 오작동 가능
	. 언젠가는 재사용 해야 함
	  - 아무도 remove된 node를 가리키지 않을 때
	  - remove 시점에서 중복실행 중인 모든 메소드의 호출이 종료되었을 때

shared_ptr
- C++11에서 제공하는 일종의 스마트 포인터
- 객체에 reference counter를 두고 이를 통해 앞으로 쓰이지 않을 객체를 판별해서 자동 삭제
- reference counter 증감을 atomic하게 구현
- 그러나 shared_ptr 객체를 load, store하는 것이 atomic이 아니다.
	. auto curr = prev->next;
	  다른 쓰레드가 그동안 prev->next를 바꿀 수 있다. 따라서 atomic하지 않다.
	. 대입 연산자를 실행하기 위해 memory copy를 해야 한다. 이 것이 atomic이 아니다.
- 해결법 -> load, store를 atomic하게 수행한다.
	. shraed_ptr<Node> curr = atomic_load(&prev->next);
	. atomic_exchange(&prev->next, new_node);
너무 느리다
- atomic_load와 atomic_exchange가 하나의 lock으로 구현되어 있다.
	. 프로그램 내부의 모든 atomic_load와 atomic_exchange가 하나의 lock
-> shared_ptr 각각이 별도의 lock을 갖도록 atomic_shared_ptr을 정의해서 사용한다.
그래도 느리다
- atomic_shared_ptr의 access는 느리다.
	. mutex를 사용하니까. blocking
	. 세밀한 동기화와 다를 것이 없다.
-> 효율적인 atomic_shared_ptr가 필요하다.
	. non-blocking 구현


비멈춤 동기화 (nonblocking synchronization)
Lock-Free 알고리즘이란?
- 여러 개의 쓰레드에서 동시에 호출했을 때에도 정해진 단위시간마다 적어도 한 개의 호출이 완료되는 알고리즘.
- 자료구조 및 그것에 대한 접근 방법
	. Queue: enqueue, dequeue
	. Stack: push, pop
	. 이진 트리: insert, delete, search
- 멀티쓰레드에서 동시에 호출해도 정확한 결과를 만들어 주는 알고리즘
	. STL 탈락
	. atomic한 동작
- Non-Blocking 알고리즘
	. 다른 쓰레드가 어떤 상태에 있건 상관없이 호출이 완료된다.
- 호출이 다른 쓰레드와 충돌하였을 경우 적어도 하나의 승자가 있어서, 승자는 delay없이 완료된다.
- 추가 상식
	. Lock을 사용하지 않는다고 lock-free 알고리즘이 아니다.
	. Lock을 사용하면 무조건 lock-free 알고리즘이 아니다.
- Wait-Free란?
	. 호출이 다른 쓰레드와 충돌해도 모두 delay없이 완료된다.

Blocking 알고리즘
- 다른 쓰레드에서 무언가 하기를 대기한다.
- 여러 가지 이유로 다른 쓰레드의 작업이 지연될 수 있다.

CAS
- CAS 없이는 대부분의 Non-blocking 알고리즘들을 구현할 수 없다.
	. Queue, Stack, List
- CAS를 사용하면 모든 싱글쓰레드 알고리즘들을 Lock-Free 알고리즘으로 변환할 수 있다.
- Lock-Free 알고리즘의 핵심
- CAS는 다른 쓰레드와의 충돌을 검사하는 알고리즘이다.
	. CAS(&A, OLD, NEW)
	. A의 값이 OLD이면 A를 NEW로 바꾸고 True 리턴
	. 다른 의미 : A 메모리를 다른 쓰레드가 먼저 업데이트했다. 모든 것을 포기하라.
- Lock-Free 알고리즘은 어떻게 구현되는가?
- 알고리즘의 동작이란?
	. 기존의 자료구조의 구성을 다른 구성으로 변경하거나 자료구조에서 정보를 얻어내는 행위

Lock-Free 알고리즘은 어떻게 구현하는가?
- 상상속의 구현
	1. 자료구조의 변경을 시도한다.
	2. 성공했는가? (?) -> 완료
	3. 시도 전으로 되돌아간다. (?)
- 앞의 알고리즘이 불가능하므로
	1. 현재의 자료구조를 파악한다.
	2. atomic하게 자료구조의 변경을 시도한다.
	   but 다른 쓰레드가 먼저 변경했으면 시도 취소
	3. 성공했는가? -> 완료
	4. 시도 전으로 되돌아간다.
	. while문을 빙글빙글 도는데 blocking 아니냐?
	. 아니다. 두 쓰레드가 동시에 접근했을 때 모든 쓰레드가 빙글빙글 도는게 아니라
	  한 쓰레드는 미리 완료를 한다.
	. lock과 비교해 보자. lock은 다른 쓰레드가 lock을 획득한 채로 
	  context switching 당하게 되면 모든 쓰레드가 놀게 된다. 
	. 그러나 lockfree 알고리즘의 경우는 다른 쓰레드가 context switching 
	  당했다 하더라도 정상적으로 일을 한다.
- atomic하게 자료구조의 변경을 시도한다. but 다른 쓰레드가 먼저 변경했으면 시도 취소
	. 알고리즘이 많이 복잡하다.
	. 그래서 작성 시 실수하기가 쉽다.
	. 실수를 적발하기가 어렵다.
	  - 하루에 한두 번 서버 크래시
	  - 가끔 가다가 아이템 증발
	. 제대로 동작하는 것이 증명된 알고리즘을 사용해야 한다.
- 믿을 수 있는 non-blocking container들을 사용하라.
	. Intel TBB, Visual Studio PPL
- 자신을 포함한 출처가 의심스러운 알고리즘은 정확성을 증명하고 사용하라
	. 정확성이 증명된 논문에 있는 알고리즘은 OK.