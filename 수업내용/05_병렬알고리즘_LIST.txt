목표
- Non Blocking 자료 구조의 제작 실습
- 일반 자료구조를 멀티쓰레드 자료구조로 변환한다.
- Blocking 자료구조로부터 시작하여 단계별로 성능향상 기법을 적용한다.
- 최종적으로 Lock Free 자료구조를 제작한다.
- 각 자료구조의 성능을 비교한다.

목표 자료구조
- SET
	. 아이템의 중복을 허용하지 않는다.
	. 정렬되어 저장된다. (unordered_set이 아니다)
	  - 검색 효율이 증가한다.
	. 삽입 삭제의 효율성을 위해 연결리스트로 구현된다.
- 구현할 메소드
	. add(x) : 집합에 x 추가, 성공시 true 반환
	. remove(x) : 집합에서 x 제거, 성공시 true 반환
	. contains(x) : 집합에 x가 있다면 true 반환

추가적인 구현
- 보초 노드
	. 검색의 효율성을 위해 항상 존재하는 Head와 Tail 노드를 갖도록 한다.
	. Head는 MAXINT, Tail은 -MAXINT를 키로 갖는다.

구현 차례
성긴 동기화 (coarse-grained synchronization)
- Lock 하나로 동기화 객체 전체를 감싸는 경우
- 성능 향상이 있을 수가 없다.


세밀한 동기화 (fine-grained synchronization)
- 전체 리스트를 한꺼번에 잠그는 것보다 개별 노드를 잠그는 것이 병행성을 향상시킬 수 있다.
	  - 전체 리스트에 대한 잠금을 두는 것이 아니라, 각각의 노드에 잠금을 둔다.
	  - Node에 Lock()과 Unlock() 메소드를 구현해야 한다.
	  - Node의 next field를 변경할 경우에는 반드시 lock을 얻은 후 변경해야 한다.
- 주의점
	. Add()와 Remove() 시점의 Pred, Curr가 가리키는 노드는 locking이 되어 있어야 한다.
	. Head부터 Node 이동을 할 때 lock을 잠그면서 이동해야 한다.
	  - 예를 들어 a의 잠금을 풀고 나서 b의 잠금을 한다면 그 사이에 다른 쓰레드의 의해
	    b가 제거될 수 있다.
	  - 즉 이동 시 prev가 잠금상태일 동안 curr의 잠금을 획득한다.
	. 병렬성이 있다.
	  - 그러나 잠금의 획득과 해제가 너무 빈번하다.
	  - 리스트가 길어지는 경우 성능이 매우 떨어진다.
	  - 무조건 head부터 시작하기 때문에 head에 bottle neck이 걸린다.


낙천적인 동기화 (optimistic synchronization)
- 세밀한 동기화의 성능 저하 원인
	. 잠금의 획득과 해제가 너무 빈번하다.
	. 리스트가 길어지는 경우 성능이 매우 떨어진다.
- 해결 아이디어
	. 이동 시 잠금을 하지 않는다.
	. Add/Remove를 위해 prev를 수정하기 전에 prev를 잠근다.
- 이동 시 잠금을 하지 않는다. -> 오동작의 가능성이 있다.
- add/remove를 위해 prev를 수정하기 전에 prev를 잠근다.
- 이동 시 잠금을 하지 않는다
	. Data Race
	. 세밀한 동기화에서 이동 시 잠그는 이유가 있음.
- 해결
	. Crash (또는 무한루프)
	  - 제거된 Node의 Next가 Crash를 발생시키는 값을 갖지 않게 한다.
	  - 제거된 Node라도 Next를 따라가면 Tail이 나오게 한다.
	. 오동작
	  - prev와 curr를 잠근 후 제대로 잠갔는지 검사. (validation)
	  - prev와 curr를 잘못 잠갔을 경우 처음부터 다시 실행
- 구현 (임시 해결)
	. 제거된 노드를 'delete'하지 않는다.
	  - next 필드의 오염 방지, 결국엔 Tail 만남
	  - 하지만 memory lock -> 나중에 해결
	. validation 조건 검사
	  - 잠겨진 prev와 curr가 제거되지 않았고
	  - prev와 curr 사이에 다른 노드가 끼어들지 않았다.
- Validation
	1. prev, curr가 리스트에 존재한다.
	2. prev와 curr 사이에 다른 노드가 없다. (prev 다음에 curr가 있다)
	. 충분한가? 충분하다.
	  - locking이 되어 있으므로 Validation 조건이 만족된 이후에는 다른 쓰레드가 prev와 curr를
	    변경할 수 없다.
	  - 다시 검색을 실행해도 항상 같은 prev, curr가 선택된다.
	  - 따라서 add/remove 연산을 해도 안전하다.
	. 유효성 검사
	  - 다시 처음부터 검색해서 원래 prev, curr로 다시 올 수 있는지 확인한다.
	  -> prev, curr가 리스트에 존재하는지 확인
	  - prev->next == curr인 것을 확인한다.
	  -> 중간에 다른 노드가 끼어들지 않았음을 확인
- 낙천적 동기화 알고리즘은 기아를 겪을 수 있다.
	. validate가 실패하면 처음부터 다시 실행한다.
	. 다른 쓰레드들이 prev와 curr를 계속 수정하는 경우 계속 재시도를 하면서 지연될 수 있다.
	. 기아상태를 겪는 경우는 흔치 않은 경우이기 때문에 실제로는 잘 동작할 가능성이 크다.


게으른 동기화 (lazy synchronization)
- 낙천적 동기화는 lock의 횟수는 비약적으로 감소했으나 리스트를 두 번 순회해야 한다는
  눈에 보이는 오버헤드가 있다.
- 이를 극복하여 다시 순회하지 않는 알고리즘을 작성하였다.
	. validate()가 노드를 처음부터 다시 순회하지 않고 validation을 수행한다.
	. prev와 curr의 잠금은 여전히 필요하다.
- Contains() 메소드는 자주 호출되는 메소드인데 이 메소드를 wait-free로 만들 수 있으면 좋겠다.
	. 목적이 아니라 부수효과에 가까움
- 각 노드에 marked 필드를 추가하여 그 노드가 집합에서 제거되어 있는지 표시한다.
	. marked가 true이면 제거되었다는 표시
	. marking을 실제 제거보다 반드시 먼저 수행한다.
	  - 또한 marking은 잠금을 획득한 후 수행된다.
	. 순회를 할 때 대상 노드를 잠글 필요가 없고 노드가 head에서 접근할 수 있는지 확인하기 위해
	  전체 리스트를 다시 순회하지 않아도 된다.
- 다음 명제가 반드시 성립한다.
	. marking되어있지 않은 모든 Node는 실제 리스트에 존재하는 살아있는 Node이다.
	. validate에서의 marking 검사는 locking 이후에 이루어지므로 validate가 OK이면 안전하다.

- 단점
	. 게으른 알고리즘은 Blocking이다.
	. 한 쓰레드가 lock을 얻은 채로 지연되면, 다른 쓰레드 역시 지연되게 된다. (convoying)
- 주의
	. flag를 사용할 때 메모리 업데이트 순서가 중요하므로 volatile


메모리 릭의 해결
- Free List
	. Delete하지 않고 모아 놓음
	  - marking이 해제되는 순간 오작동 가능
	. 언젠가는 재사용 해야 함
	  - 아무도 remove된 node를 가리키지 않을 때
	  - remove 시점에서 중복실행 중인 모든 메소드의 호출이 종료되었을 때

shared_ptr
- C++11에서 제공하는 일종의 스마트 포인터
- 객체에 reference counter를 두고 이를 통해 앞으로 쓰이지 않을 객체를 판별해서 자동 삭제
- reference counter 증감을 atomic하게 구현
- 그러나 shared_ptr 객체를 load, store하는 것이 atomic이 아니다.
	. auto curr = prev->next;
	  다른 쓰레드가 그동안 prev->next를 바꿀 수 있다. 따라서 atomic하지 않다.
	. 대입 연산자를 실행하기 위해 memory copy를 해야 한다. 이 것이 atomic이 아니다.
- 해결법 -> load, store를 atomic하게 수행한다.
	. shraed_ptr<Node> curr = atomic_load(&prev->next);
	. atomic_exchange(&prev->next, new_node);
너무 느리다
- atomic_load와 atomic_exchange가 하나의 lock으로 구현되어 있다.
	. 프로그램 내부의 모든 atomic_load와 atomic_exchange가 하나의 lock
-> shared_ptr 각각이 별도의 lock을 갖도록 atomic_shared_ptr을 정의해서 사용한다.
그래도 느리다
- atomic_shared_ptr의 access는 느리다.
	. mutex를 사용하니까. blocking
	. 세밀한 동기화와 다를 것이 없다.
-> 효율적인 atomic_shared_ptr가 필요하다.
	. non-blocking 구현


비멈춤 동기화 (nonblocking synchronization)
먼저 복습
현실의 멀티쓰레드 프로그램은?
- 여러 쓰레드가 동시에 멀티 코어에서 실행된다
- 쓰레드간의 데이터 공유 및 동기화는 안전한 lock-free 자료구조를 통해서 이루어진다.
Lock-Free 알고리즘이란?
- 여러 개의 쓰레드에서 동시에 호출했을 때에도 정해진 단위시간마다 적어도 한 개의 호출이 완료되는 알고리즘.
- 자료구조 및 그것에 대한 접근 방법
	. Queue: enqueue, dequeue
	. Stack: push, pop
	. 이진 트리: insert, delete, search
- 멀티쓰레드에서 동시에 호출해도 정확한 결과를 만들어 주는 알고리즘
	. STL 탈락
	. atomic한 동작
- Non-Blocking 알고리즘
	. 다른 쓰레드가 어떤 상태에 있건 상관없이 호출이 완료된다.
- 호출이 다른 쓰레드와 충돌하였을 경우 적어도 하나의 승자가 있어서, 승자는 delay없이 완료된다.
- 추가 상식
	. Lock을 사용하지 않는다고 lock-free 알고리즘이 아니다.
	. Lock을 사용하면 무조건 lock-free 알고리즘이 아니다.
- Wait-Free란?
	. 호출이 다른 쓰레드와 충돌해도 모두 delay없이 완료된다.

Blocking 알고리즘
- 다른 쓰레드에서 무언가 하기를 대기한다.
- 여러 가지 이유로 다른 쓰레드의 작업이 지연될 수 있다.

CAS
- CAS 없이는 대부분의 Non-blocking 알고리즘들을 구현할 수 없다.
	. Queue, Stack, List
- CAS를 사용하면 모든 싱글쓰레드 알고리즘들을 Lock-Free 알고리즘으로 변환할 수 있다.
- Lock-Free 알고리즘의 핵심
- CAS는 다른 쓰레드와의 충돌을 검사하는 알고리즘이다.
	. CAS(&A, OLD, NEW)
	. A의 값이 OLD이면 A를 NEW로 바꾸고 True 리턴
	. 다른 의미 : A 메모리를 다른 쓰레드가 먼저 업데이트했다. 모든 것을 포기하라.
- Lock-Free 알고리즘은 어떻게 구현되는가?
- 알고리즘의 동작이란?
	. 기존의 자료구조의 구성을 다른 구성으로 변경하거나 자료구조에서 정보를 얻어내는 행위

Lock-Free 알고리즘은 어떻게 구현하는가?
- 상상속의 구현
	1. 자료구조의 변경을 시도한다.
	2. 성공했는가? (?) -> 완료
	3. 시도 전으로 되돌아간다. (?)
- 앞의 알고리즘이 불가능하므로
	1. 현재의 자료구조를 파악한다.
	2. atomic하게 자료구조의 변경을 시도한다.
	   but 다른 쓰레드가 먼저 변경했으면 시도 취소
	3. 성공했는가? -> 완료
	4. 시도 전으로 되돌아간다.
	. while문을 빙글빙글 도는데 blocking 아니냐?
	. 아니다. 두 쓰레드가 동시에 접근했을 때 모든 쓰레드가 빙글빙글 도는게 아니라
	  한 쓰레드는 미리 완료를 한다.
	. lock과 비교해 보자. lock은 다른 쓰레드가 lock을 획득한 채로 
	  context switching 당하게 되면 모든 쓰레드가 놀게 된다. 
	. 그러나 lockfree 알고리즘의 경우는 다른 쓰레드가 context switching 
	  당했다 하더라도 정상적으로 일을 한다.
- atomic하게 자료구조의 변경을 시도한다. but 다른 쓰레드가 먼저 변경했으면 시도 취소
	. 하지만 2개의 변수에 동시에 CAS를 적용할 수는 없다.
	. 알고리즘이 많이 복잡하다.
	. 그래서 작성 시 실수하기가 쉽다.
	. 실수를 적발하기가 어렵다.
	  - 하루에 한두 번 서버 크래시
	  - 가끔 가다가 아이템 증발
	. 제대로 동작하는 것이 증명된 알고리즘을 사용해야 한다.
- 믿을 수 있는 non-blocking container들을 사용하라.
	. Intel TBB, Visual Studio PPL
- 자신을 포함한 출처가 의심스러운 알고리즘은 정확성을 증명하고 사용하라
	. 정확성이 증명된 논문에 있는 알고리즘은 OK.

다시 비멈춤 동기화
- 게으른 동기화를 통해 만족할 만한 멀티쓰레드 성능향상을 얻었다.
- 하지만 Blocking 구현이어서 성능향상의 여지가 있고, Priority Inversion이나
  Convoying에서 자유롭지 못하다.
- Non-Blocking 구현은 게으른 동기화에서 출발한다.
	. Lock-Free 기법을 사용할 때 이용하는 여러 기법들이 적용되어 있다.
	. Lock으로 보호 받는 임계 영역을 CAS로 대체해야 하는데, 임계 영역 구간이 충분히 작아졌다.

- Lock을 사용하지 않는다.
- 서로 충돌하는 thread는 CAS로 승부를 낸다.
	. CAS 성공
	-> 무조건 method가 성공적으로 종료해야 한다.
	  - 적어도 이전보다는 더 진전된 상태로 바뀌어야 한다.
	. CAS 실패
	-> 다른 쓰레드에서 먼저 자료구조를 수정했다는 이야기이므로 지금까지 수집한 자료구조
	    정보를 더 이상 사용할 수 없고, 다시 수집해야 한다.
- CAS 한방에 validation 검사 & 수정이 이뤄져야 함.

ADD에서 고려해야 할 것
- 다른 쓰레드에서 prev를 remove해 버렸다.
	. prev의 marking을 확인하면서 변경해야 한다.
	. 실제로는 prev 이전 노드에 삽입되어야 함.
	. prev의 mark가 false인 것을 '확인하면서' 변경해야 한다.
- 다른 쓰레드에서 prev, curr 사이에 새로운 노드를 끼워 넣었다.
	. prev의 next가 curr인 것을 '확인하면서' 변경해야 한다.
의문점
- prev와 curr를 locking하지 않기 때문에 당연히 발생할 수 있는 불상사들
- 이를 검출하려면 next와 marking을 동시에 감시하면서 CAS를 수행하면 된다.
	. 즉 next와 marking을 다른 쓰레드가 건드렸다면 아무것도 하지 않고 처음부터 다시 수행해야 한다.
	. next와 marking을 동시에 CAS해야 한다.
	. 그런 연산은 x86 CPU에 존재하지 않는다.
동시 CAS의 구현
- CAS의 한계
	. 한 번에 하나의 변수밖에 바꾸지 못한다.
	. marking과 next의 atomic한 동시 변환이 가능해야 한다.
- 극복
	. 한 장소(word)에 주소와 marking을 동시에 저장
	. 주소와 marking을 access하는 별도의 api 작성
- 일종의 꼼수, 특수한 경우에만 사용 가능
유사 멀티CAS 구현
- 32비트 주소 중 LSB를 마크로 사용(1비트를 mark로 사용)
	. 64비트 주소 중 실제 48비트만 사용하고 16비트는 사용하지 않는다.
	. 48비트 중 앞 2비트도 사용하지 않는다. 왜냐하면 
	. 주소는 무조건 4의 배수이다(C 표준)
	. 64비트에서는 무조건 8의 배수이다. (C++ 표준)
	. 이 사용하지 않는 2비트를 마크로 사용하자.

Remove에서 고려해야 할 것
- curr를 delete하려면 두 단계가 필요하다.
	. curr를 마킹하고 (CAS 사용)
	. prev의 next를 curr의 next로 변경한다. (CAS 사용)
	. 한마디로 curr(mark)와 prev(next)를 동시에 변경해야 한다.
- 하지만 우리는 prev와 curr을 잠그지 못한다.
	. 따라서 위의 2번째 과정에서 실패할 수 있다.
	. curr를 마킹한 순간 다른 쓰레드가 prev를 지울 수 있다.
	  - 후처리 필요
	  -> 마킹되지 않은 이전 노드를 찾아서 next를 curr의 next로 변경해야 한다.
	  -> 이 과정에서 다른 쓰레드들과 충돌할 수도 있고, 이를 해결하려면 알고리즘이 복잡해진다.
	. prev와 curr 사이에 다른 노드가 추가되었을 수도 있다.

현실적인 대안 : 정책 변경
- remove시 제거를 시도하지만 실패하면 무시한다.
	. 리스트 중간 중간에 marking된 노드가 존재하는 것을 받아들인다.
	. 리스트의 정의를 변경하고, 변경된 리스트에서도 올바르게 동작하도록 모든 메소드를 수정한다.
	-> marking까지는 반드시 필요하지만 제거가 필요할까?
- Add(), Remove(), Contains() 메소드를 마킹되었지만 Remove되지 않는 노드가 있는 경우에도
  동작하도록 수정한다.
	. 마킹된 노드를 고려한 수정은 너무 어렵다.
	. 메소드 호출 시(검색 시) 마킹된 노드를 제거하고 진행한다.
	  - 제거하면서 검색한다.
	. 찌꺼기 검색의 책임이 Remove()에만 있지 않다.

Lock-Free List의 메모리 릭
- Lazy와 같다.
- 메소드 실행 중에 참조하고 있는 노드가 재사용 되는 경우 오동작의 위험성이 매우 높다
재사용을 위해서는?
- Free List를 사용한다.
- shared_ptr를 사용한다.

Free-List
- Non Blocking에서 사용하기 위해서는 Non Blocking Free List로 구현해야 한다.
- Free List에 있는 Node 재사용
	. 재사용하지 않으면 Memory Leak과 다를 바 없다.
	. 제한 없이 재사용 한다면?
	  - Remove()에서 넣은 것을 Add()에서 다시 사용
	  - Free List에 넣지 않고 그냥 delete하는 것과 같다.
	  - 알고리즘이 오동작 : 검색에서 밟고 지나가는 노드가 다른 곳에 가서 붙는다.
	  - 안전하게 재사용하려면 모든 쓰레드가 종료했을 때 재사용하면 된다.
	  - 게임 서버에서는 사용할 수 없다.

메모리 릭의 해결 방법
- atomic shared_ptr
- stamped pointer
- EPOCH
- Hazard Pointer

shared_ptr
- Lock-Free List에서 사용 가능한가? -> No
	. 우리는 합성 포인터 자료구조를 사용하고 있다.
- 느리다.
	. 일반적인 포인터의 load, store는 32비트 integer의 load, store와 같다.
	. 하지만 shared_ptr의 store는 atomic counter의 두 번 업데이트를 필요로 한다.
	  - 기존 데이터의 counter 감소, 새 데이터의 counter 증가
- 그래서
	. 지역 변수는 atomic이 아닌 일반 shared_ptr을 사용한다.
	. 함수의 파라미터로 const reference를 사용한다.
- atomic하지 않다.
	. counter의 관리는 atomic하다.
	. pointer 자체의 접근이 atomic하지 않다.
- 그래서
	. atomic_shared_ptr를 사용한다.
	. 상용 atomic_shared_ptr를 구매해서 사용한다.
	. 주의해서 atomic하게 사용한다.

EPOCH
- 쓰레드가 종료하지 않아도 재사용 가능 여부를 판단할 수 있도록 했다.
- 재사용 가능하다. -> Remove 된 노드를 Access하는 포인터가 모든 쓰레드에서 존재하지 않는다.
- 재사용 불가능하다. -> Remove된 노드를 Access하는 쓰레드가 존재해서, 재사용 결과
  그 노드의 값이 변경될 때 그 쓰레드가 오작동한다.
- Remove되는 순간에 다른 쓰레드들에서 실행 중인 메소드들이 다 종료하면, Remove된 Node를
  가리키는 포인터는 존재하지 않는다.
- Rmove되는 Node에 현재 시간을 저장하고, 모든 쓰레드에서 메소드들의 
  시작시간과 종료시간을 적으면 판단이 가능하다.