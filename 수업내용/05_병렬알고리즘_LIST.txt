목표
- Non Blocking 자료 구조의 제작 실습
- 일반 자료구조를 멀티쓰레드 자료구조로 변환한다.
- Blocking 자료구조로부터 시작하여 단계별로 성능향상 기법을 적용한다.
- 최종적으로 Lock Free 자료구조를 제작한다.
- 각 자료구조의 성능을 비교한다.

목표 자료구조
- SET
	. 아이템의 중복을 허용하지 않는다.
	. 정렬되어 저장된다. (unordered_set이 아니다)
	  - 검색 효율이 증가한다.
	. 삽입 삭제의 효율성을 위해 연결리스트로 구현된다.
- 구현할 메소드
	. add(x) : 집합에 x 추가, 성공시 true 반환
	. remove(x) : 집합에서 x 제거, 성공시 true 반환
	. contains(x) : 집합에 x가 있다면 true 반환

추가적인 구현
- 보초 노드
	. 검색의 효율성을 위해 항상 존재하는 Head와 Tail 노드를 갖도록 한다.
	. Head는 MAXINT, Tail은 -MAXINT를 키로 갖는다.

구현 차례
- 성긴 동기화 (coarse-grained synchronization)
	. Lock 하나로 동기화 객체 전체를 감싸는 경우
	. 성능 향상이 있을 수가 없다.

세밀한 동기화 (fine-grained synchronization)
- 전체 리스트를 한꺼번에 잠그는 것보다 개별 노드를 잠그는 것이 병행성을 향상시킬 수 있다.
	  - 전체 리스트에 대한 잠금을 두는 것이 아니라, 각각의 노드에 잠금을 둔다.
	  - Node에 Lock()과 Unlock() 메소드를 구현해야 한다.
	  - Node의 next field를 변경할 경우에는 반드시 lock을 얻은 후 변경해야 한다.
	. Add()와 Remove() 시점의 Pred, Curr가 가리키는 노드는 locking이 되어 있어야 한다.
	. Head부터 Node 이동을 할 때 lock을 잠그면서 이동해야 한다.
	. 병렬성이 있다.
	  - 그러나 잠금의 획득과 해제가 너무 빈번하다.
	  - 리스트가 길어지는 경우 성능이 매우 떨어진다.
	  - 무조건 head부터 시작하기 때문에 head에 bottle neck이 걸린다.

낙천적인 동기화 (optimistic synchronization_
- 이동 시 잠금을 하지 않는다. -> 오동작의 가능성이 있다.
- add/remove를 위해 prev를 수정하기 전에 prev를 잠근다.
- 이동 시 잠금을 하지 않는다
	. Data Race
	. 세밀한 동기화에서 이동 시 잠그는 이유가 있음.
- 해결
	. Crash (또는 무한루프)
	  - 제거된 Node의 Next가 Crash를 발생시키는 값을 갖지 않게 한다.
	  - 제거된 Node라도 Next를 따라가면 Tail이 나오게 한다.
	. 오동작
	  - prev와 curr를 잠근 후 제대로 잠갔는지 검사. (validation)
	  - prev와 curr를 잘못 잠갔을 경우 처음부터 다시 실행
- 구현 (임시 해결)
	. 제거된 노드를 'delete'하지 않는다.
	  - next 필드의 오염 방지, 결국엔 Tail 만남
	  - 하지만 memory lock -> 나중에 해결
	. validation 조건 검사
	  - 잠겨진 prev와 curr가 제거되지 않았고
	  - prev와 curr 사이에 다른 노드가 끼어들지 않았다.
- Validation
	1. prev, curr가 리스트에 존재한다.
	2. prev와 curr 사이에 다른 노드가 없다.
	. 충분한가? 충분하다.
	. 유효성 검사
	  - 다시 처음부터 검색해서 원래 prev, curr로 다시 올 수 있는지 확인한다.
	  -> prev, curr가 리스트에 존재하는지 확인
	  - prev->next == curr인 것을 확인한다.
	  -> 중간에 다른 노드가 끼어들지 않았음을 확인
- 낙천적 동기화 알고리즘은 기아를 겪을 수 있다.
	. validate가 실패하면 처음부터 다시 실행한다.
	. 다른 쓰레드들이 prev와 curr를 계속 수정하는 경우 계속 재시도를 하면서 지연될 수 있다.
	. 기아상태를 겪는 경우는 흔치 않은 경우이기 때문에 실제로는 잘 동작할 가능성이 크다.


게으른 동기화 (lazy synchronization)
- 낙천적 동기화는 lock의 횟수는 비약적으로 감소했으나 리스트를 두 번 순회해야 한다는
  눈에 보이는 오버헤드가 있다.
- 이를 극복하여 다시 순회하지 않는 알고리즘을 작성하였다.
	. validate()가 노드를 처음부터 다시 순회하지 않고 validation을 수행한다.
	. prev와 curr의 잠금은 여전히 필요하다.
- Contains() 메소드는 자주 호출되는 메소드인데 이 메소드를 wait-free로 만들 수 있으면 좋겠다.
	. 목적이 아니라 부수효과에 가까움
- 각 노드에 marked 필드를 추가하여 그 노드가 집합에서 제거되어 있는지 표시한다.
	. marked가 true이면 제거되었다는 표시
	. marking을 실제 제거보다 반드시 먼저 수행한다.
	  - 또한 marking은 잠금을 획득한 후 수행된다.
	. 순회를 할 때 대상 노드를 잠글 필요가 없고 노드가 head에서 접근할 수 있는지 확인하기 위해
	  전체 리스트를 다시 순회하지 않아도 된다.
- 다음 명제가 반드시 성립한다.
	. marking되어있지 않은 모든 Node는 실제 리스트에 존재하는 살아있는 Node이다.
	. validate에서의 marking 검사는 locking 이후에 이루어지므로 validate가 OK이면 안전하다.

- 단점
	. 게으른 알고리즘은 Blocking이다.
	. 한 쓰레드가 lock을 얻은 채로 지연되면, 다른 쓰레드 역시 지연되게 된다. (convoying)
- 주의
	. flag를 사용할 때 메모리 업데이트 순서가 중요하므로 volatile

메모리 릭의 해결
- Free List
	. Delete하지 않고 모아 놓음
	  - marking이 해제되는 순간 오작동 가능
	. 언젠가는 재사용 해야 함
	  - 아무도 remove된 node를 가리키지 않을 때
	  - remove 시점에서 중복실행 중인 모든 메소드의 호출이 종료되었을 때

shared_ptr
- C++11에서 제공하는 일종의 스마트 포인터
- 객체에 reference counter를 두고 이를 통해 앞으로 쓰이지 않을 객체를 판별해서 자동 삭제
- reference counter 증감을 atomic하게 구현
- 그러나 shared_ptr 객체를 load, store하는 것이 atomic이 아니다.
	. auto curr = prev->next;
	  다른 쓰레드가 그동안 prev->next를 바꿀 수 있다. 따라서 atomic하지 않다.
	. 대입 연산자를 실행하기 위해 memory copy를 해야 한다. 이 것이 atomic이 아니다.
- 해결법 -> load, store를 atomic하게 수행한다.
	. shraed_ptr<Node> curr = atomic_load(&prev->next);
	. atomic_exchange(&prev->next, new_node);
너무 느리다
- atomic_load와 atomic_exchange가 하나의 lock으로 구현되어 있다.
	. 프로그램 내부의 모든 atomic_load와 atomic_exchange가 하나의 lock
-> shared_ptr 각각이 별도의 lock을 갖도록 atomic_shared_ptr을 정의해서 사용한다.
그래도 느리다
- atomic_shared_ptr의 access는 느리다.
	. mutex를 사용하니까. blocking
	. 세밀한 동기화와 다를 것이 없다.
-> 효율적인 atomic_shared_ptr가 필요하다.
	. non-blocking 구현

비멈춤 동기화

