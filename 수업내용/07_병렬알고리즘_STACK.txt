Stack
- 후입선출 구조
- Push(), Pop() 메서드를 제공
- 성능은 큐보다 좋다. (캐시 친화적)

무제한 성긴 동기화 스택
- 연결 리스트로 구성되고 top 필드가 첫 노드를 가리킨다.
- 만약 스택이 비어있을 경우는 nullptr (보초 노드를 넣을 필요가 없다)
- -1을 스택에 추가하는 것은 고려하지 않는다.
- empty일 경우 pop()은 -2를 리턴한다.

무제한 무잠금 스택
- CAS를 이용하여 구현한다.
- Top의 변환을 CAS를 사용하여 non-blocking으로 구현한다.
- ABA 문제가 있으므로 delete를 하지 않는다.

- 메소드 호출은 스택의 top에 대해 성공한 CAS호출의 순서로 하나씩 진행되므로
  순차병목현상이 나타날 수 있다.
- new와 delete를 사용하면 ABA 문제가 생긴다.
	. Queue보다 문제가 생길 확률이 크다.

CAS 동기화의 문제
- 경쟁이 심할 경우 CAS 실패시 계속 재시도하는 것은 전체 시스템의 악영향을 줌
	. Thread가 많아질 수록 경쟁이 심해짐
	. 경쟁이 심할 경우 CAS가 실패할 확률이 높음
	  - 실패할 경우 성공할 때 까지 반복
	. CAS를 실행할 경우 같은 CPU의 모든 Core의 메모리 접근이 중단됨
	  - thread가 많아질 수록 잦은 메모리 접근 중단

BackOff
- 경쟁이 심할 경우 경쟁을 줄이자.
	. CAS의 실패는 경쟁이 심함을 뜻함.
	. CAS가 실패했을 경우 적절한 기간 동안 실행을 멈추었다가 재개하자.
	. CAS의 실패 확률이 낮아짐 -> 메모리 접근 중단 감소
- 적절한 기간
	. 처음에는 짧게
	. 계속 실패하면 점점 길게
	. 첫 번 시도에 성공하면 짧게
	. thread마다 기간을 다르게 해야 한다.
- 시스템 콜을 호출하는 오버헤드가 너무 크다.
	. CAS 몇 백 번을 막는 수준
	. chrono::high_resolution_clock을 사용한다.
	. (윈도우에서는 syscall을 하지 않지만 다른 곳에서 안한다는 보장이 없다)
	. 자체 루프
	. CPU 내장 타이머를 사용하자. (RDTSC, CPU 클럭에 비례함)

소거 백오프 스택
병행성 문제
- Queue나 Stack은 리스트의 말단 부분에서 잦은 충돌이 생긴다.
	. fine grain 타입의 최적화가 불가능하다.
	. Queue는 1/2로 충돌이 분산된다.
- Stack의 경우 충돌을 회피해서 병렬로 처리하는 방법이 가능
	. push, pop이 동시에 발생하는 경우 꼭 Stack에 넣어야 하나?
소거
- 많은 쓰레드가 서로 충돌할 경우 Stack에 넣지 않고 직접 Data를 주고 받도록 한다.
	. Stack을 통하지 말고 다른 객체를 통해 전달
- Lock-Free로 데이터를 주고 받도록 한다.
- 높은 경쟁률에 대비하여 주고 받는 별도의 객체를 복수로 준비한다.
- 만약 push와 pop이 거의 동시에 실행된다면 두 연산은 서로 취소되어 없어지고 스택에 접근하지 않는다.
- 이런 경우 push를 호출하는 쓰레드는 스택의 변동 없이 pop을 호출하는 쓰레드와 값을 교환할 수 있다.
	. 이 때 서로를 소거(Eliminate)하게 된다고 한다.

EliminationArray
- 원소 : 자료교환의 장소
- 여러 개의 원소를 갖고 부하를 분산
	. 서로 만나지 못할 경우도 있다.
	. 경쟁이 심할 경우 많은 장소가 효율적이고, 경쟁이 적을 경우는 장소가 적어야 한다.
쓰레드는 EliminationArray에서 임의(Random)의 항목을 골라서, 서로를 소거하려 시도
- 잘못된 종류의 호출을 만난 경우는 소거 실패
	. 예) push와 push, pp과 pop
- 임의로 하지 않고, 짝을 잘 맞추어 주면?
	. 정보 전달 자체가 오버헤드
	. Lock-Free로 하는 것은 어렵다. Open-Problem
Stack - Lock-Free BackOff에서 BackOff를 사용하지 않고, 대신에 소거를 시도한다.
- Elimination Array의 임의의 원소를 선택한다.
	. 임의 : 협조 자체가 오버헤드
	. Array의 크기는 가변
- 소거 시도
	. 아무도 없으면 기다림 (?)
	. 다른 쓰레드가 기다리고 있으면 교환
	. 이미 교환 중이면 재시도 (array size 증가 필요)


소거
- 많은 쓰레드가 서로 충돌할 경우 Stack에 넣지 않고 직접 Data를 주고 받도록 한다.
	. Stack을 통하지 말고 다른 객체를 통해 전달
- Lock-Free로 Data를 주고 받도록 한다.
- 높은 경쟁률에 대비하여 주고 받는 별도의 객체를 복수로 준비한다.

구현
- Slot
	. 처음 교환을 시도한 쓰레드의 입력값을 저장하는 공간
	. 두 번째 쓰레드가 자신의 값을 넘겨 주는 공간
- 교환기는 3개의 상태를 가진다.
	. EMPTY
	. WAITING
	. BUSY
	  - 나중에 온 쓰레드가 슬롯의 값을 읽어가고 자신의 값으로 변경한 상태
	  - 처음 쓰레드는 아직 읽기를 완료하지 않음.

EMPTY
- CAS를 이용하여 슬롯에 자신의 아이템을 넣고 상태를 WAITING으로 바꾸기를 시도한다.
	. 실패
	  - 다른 쓰레드가 이미 CAS를 성공한 경우이다.
	  - 다른 쓰레드가 WAITING으로 변경
	  - 처음부터 다시 시도
	. 성공
	  - 스핀을 하면서(Blocking?) 다른 쓰레드가 교환을 끝내길 기다림
	  
ABA 문제
- 해당 알고리즘은 ABA문제를 일으키지 않는다.
	. ABA현상이 발생한다.
	. 하지만 그냥 진행해도 문제없다.
	. 교환대상이 바뀐 것 뿐이고 값도 그대로이기 때문에 아무 문제 없다.
	  - 사실은 CAS를 통해서 old값을 읽기 때문에 상태만 그대로이면 값이 바뀌는 것
	    까지도 문제가 없다.
타임아웃 문제
- 너무 짧은 교환 시간은 항상 실패하게 되므로 시간제한 기간을 고를 때 주의해야 한다.
	. 벤치마킹을 하면서 측정해야 한다.

소거 배열
- Exchange 객체의 배열
	. capacity개의 원소를 갖는다.
- visit()
	. 소거 배열이 갖고 있는 exchange원소 중 하나를 랜덤하게 선택해서 교환을 시도한다.
	. range값을 통해 random값의 범위를 조정할 수 있다.



SKIPLIST
지금까지의 자료구조
- Set
	. Linked List Set, 검색시간 O(n)
	. 못써먹는다.

일반적인 트리 구조
- 트리 깊이의 균형을 유지하기 위하여 정기적인 재균형 작업이 필요
	. 하지만 병행 구조에서는 재균형작업이 병목이나 경쟁상태를 유발할 가능성이 있다.

SkipList
- 평균 O(logN) 검색시간을 갖는 자료구조
- 재균형작업이 필요 없음
- 랜덤 자료구조
	. 옵티멀한 방향으로 구현하려면 다른 쓰레드가 뭐하는지 알아내서 협의를 해야하는데
	  이게 오버헤드가 너무 크다.
	. 그래서 랜덤을 사용한다. 소거할 때 어디서 소거할지 랜덤으로
- Worst Case O(n)
	. 신경을 쓰지 않아도 될 정도로 확률이 낮음

- Set을 구현할 때 사용한 연결리스트의 확장
- 노드들이 추가 포인터를 갖고 있으며, 같은 레벨의 포인터끼리 연결됨. (next->next[n])
- 추가 링크(레벨 1 이상) 지름길을 만든다.
	. 노드를 추가하거나 제거할 때 지름길을 유지한다.
- 검색을 할 때 지름길을 우선 이용한다.