- C++11
- OpenMP
- Indel Thread Building Block
- CUDA
- Transactional Memory
- 새로운 언어

C++11
- 성능 때문에 다루지 않은 것들
	. 시스템 호출로 구현되기 때문에 또는 Blocking으로 구현되므로
	. condition_variable, future, promise, async
	. coroutine
	  - 생성, 소멸 부하가 적다.

OpenMP
- C와 C++, FORTRAN에서 병렬프로그램을 가능하게 해주는 API
- 내부적으로 멀티쓰레드, 공유메모리를 사용한다.
- 컴파일러 디렉티브와 함수, 변수로 구성되어 있다.
	. 컴파일러 디렉티브: 컴파일러에게 요청(pragma pack, pragma once)
- 표준으로 지정되어있어서 대부분의 컴파일러에서 구현되어 있다.

특징
- 분산 메모리(분산 컴퓨터)에서는 사용할 수 없다.
- 최상의 공유메모리 사용 패턴을 보장하지 않는다.
- Data Dependency, Data Race, Deadlock 검사는 프로그래머가 해야 한다.
- 컴파일러가 알아서 기존 프로그램을 병렬로 변환해 주지 않는다.
  어느 부분을 어떻게 병렬화할지를 프로그래머가 지정해 주어야 한다.

프로그래밍 모델
- 공유메모리에서의 멀티쓰레드 구현
- 자동으로 병렬화를 하지 않고 사용자가 병렬화를 지정
- Fork-Join 모델
- 컴파일러 디렉티브에 의존
- Nesting 가능(병렬화의 겹침 허용)
	. 기존 쓰레드를 나눠서 잘 사용하게 해줌으로써 convoying 등 예방
- 동적 쓰레드 할당
- 메모리 일관성은 보장하지 않는다. 필요하면 FLUSH 명령을 사용해야 한다.
- FLUSH?
	. atomic_thread_fence

parallel Directive
- #pragma omp parallel
- 멀티쓰레드가 생성되어 해당하는 블록의 코드를 병렬로 수행한다.
- 블록의 끝에서 모든 쓰레드의 종료를 확인한 후 계속 진행한다.

작업(Work)
- 병렬성을 지정하는 프로그램의 단위
작업 분배 지정(Work-Sharing Construct)
- 작업을 분배하는 방식
	. Do/For : 루프를 여러 쓰레드가 나누어 수행
	. SECTIONS : 프로그램 블록으로 나누어진 작업들을 여러 쓰레드가 나누어 수행
	. SINGLE : 한 개의 쓰레드가 전담해서 수행

Do/For
- "schedule"
	. 루프가 병렬로 실행하는 방식을 지정
	. STATIC : 모든 쓰레드가 공평한 개수의 묶음을 실행
	. DYNAMIC : 먼저 끝난 쓰레드가 다음 묶음을 실행
- 묶음(chunk)
	. 쓰레드가 한번에 실행할 루프의 횟수
- "nowait"
	. 쓰레드의 실행을 동기화 하지 않음
	. 먼저 끝난 쓰레드가 다른 쓰레드의 작업종료를 기다리지 않고 다음 작업 실행

주의 사항
- For 병렬화에서 data dependency를 검사하지 않는다.
	. c[i] = c[i - 1] + a[i]; // 오동작
	. data dependency는 프로그래머의 책임



TBB
- Intel Thread Building Block
- 쓰레드 사용에 편리한 여러 API를 가짐
- Task 관리 기능 포함
- Intel CPU에서 동작함
	. 비공식적인 Android/ARM 버전도 존재함
- 최근 OneAPI라는 프로젝트에 통합되었으며, C++11과의 연동이 강조되고 있음
	. 특히 람다

TBB의 기능들
- 메모리 일관성 지시
	. 지원에서 제거됨
	. C++의 memory_order를 사용하는 것이 낫다.
- 메모리 할당자
	. 멀티쓰레드 상에서의 효율적인 메모리 할당자
	. 기존의 메모리 할당자를 교체

Loop Parallelizer(루프 병렬화?)
- OpenMP처럼 #pragma 형태가 아니므로 사용자가 Loop를
  멀티쓰레드를 적용할 수 있는 형태로 변경해야 한다.
	. 루프의 범위를 지정할 수 있어야 한다.
	. TBB가 호출할 operator를 등록해야 한다.


CUDA
- GPU 성능이 향상함에 따라 HLSL을 계산에 사용
- DX12 컴퓨트 셰이더 없이 GPU를 계산에 활용할 수 있도록 하자.

GPGPU
- CPU의 몇 십 배의 속도가 가능
	. 계산량이 많을 경우
단점
- 낮은 I/O 및 직렬 계산 속도
	. CPU와 GPU 사이의 병목 현상
	. 게임에서 쓰기 힘들다.
	. 물리엔진에서 예외적으로 쓰기도 함
- 적은 메모리 (그래픽 카드의 VRAM)
	. HAS(Hybrid System Architecture)로 극복 (CPU 내장 GPU)


Transactional Memory
병렬 하드웨어
- Hyper Thread
- Big - Little CPU
	. 부담이 적은 작업을 할 때는 Little CPU 사용 (배터리 사용량 감소)
	. P-E (Performance, Economi)
- Transactional Memory

지금까지
- 멀티 쓰레드용 자료구조를 구현하였다.
	. 리스트, 큐, 스택, 스킵리스트
- 여러 동기화 도구를 사용하여 구현했다.
	. Locking, Spinning, CAS
	. 각각의 단점이 있다.
- 크게 Blocking, NonBlocking 방식이 있다.

Blocking
- 직관적이다.
- 병렬성이 없다.
- 의도하지 않은 멈춤현상을 야기한다.
	. 우선순위 역전
	  - 높은 우선순위의 쓰레드가 잠금이 없어서 실행되지 못함
	. 호위 현상(Convoying)
	  - 잠금을 잡은 쓰레드가 실행을 멈춘 동안에는 모든 잠금을 원하는 쓰레드가
	    대기해야 한다.
- 프로그램을 주의 깊게 하지 않으면 교착상태(Deadlock)에 빠진다.
	. 여러 객체를 동시에 잠가야 할 때 문제가 생긴다.
	. 이전의 해결법 : 능숙한 프로그래머를 고용한다.
	  - 멀티 프로세서 프로그래밍이 희귀했을 때나 가능
	. 해결법 : 객체간의 순서를 정한다.
	  - 객체가 동적으로 생성되면?

Non-Blocking
- HW 도움으로 Wait Free하게 수행되는 CAS 연산을 사용
- Lock으로 인한 멈춤 현상을 회피할 수 없다
- 문제
	. 이러한 원자적인 연산으로 알고리즘이나 자료구조를 설계하는 것은 매우 어려운 일이다.
	. 프로세서가 많아질수록 CAS 연산의 부하가 커진다.
- CAS의 근본적인 문제
	. 연산의 단위가 Word이다.
	. 여러 개의 Word의 변경을 원자적으로 할 수 있으면 알고리즘의 구현이 훨씬 쉬워진다.

Lock-Free 알고리즘의 한계
- Lock-Free 구현은 확장성이 떨어진다.
	. Queue에 Copy() 메소드 추가
	. Set에 Clear() 메소드 추가
	. 모든 조합을 신경써서 기존의 메소드들을 전부 수정하여야 한다.
- 자료구조의 합성
	. 복수 개의 메소드 호출의 atomic화는 어렵다.
- 다른 자료구조 메소드들의 연속동작을 atomic하게 구현하는 것은 더 어렵다.
- Lock-Free 알고리즘의 정확성을 증명하는 것은 매우 어려운 일이다.
	. memory ordering 문제까지 겹치면 정말 어렵다.

트랜잭션(Transaction)
- 하나의 쓰레드가 실행하는 일련의 프로그램 블록(임계 영역) -> 트랜잭션으로 정의
- 각각의 트랜잭션은 atomic하다.
	. 한 번에 하나씩 실행된 것처럼 보여야 한다.
	. 교착상태를 발생시키지 않는다.
- DB의 트랜잭션 개념과 같음

복사본과 원본 사이에 차이가 있나 확인한다.
차이가 있으면 실행을 무효화한다.